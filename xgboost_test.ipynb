{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pd.read_csv('./data/test.csv')\n",
    "FEATURE_COLS = feat.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_file_path = './data/test_df.pickle'\n",
    "\n",
    "# with open(pickle_file_path, 'rb') as f:\n",
    "#     test_df = pickle.load(f)\n",
    "\n",
    "pickle_file_path = './data/train_testi_df.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testi = train_df[:2000]\n",
    "train_df = train_df[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_data(df):\n",
    "    # Oletetaan, että FEATURES_COLS on jo määritelty olemassa oleville piirteille\n",
    "    data = [df[col].values for col in FEATURE_COLS]\n",
    "    # Lisää mallin piirteet\n",
    "    data.append(np.vstack(df['combined_features'].values))\n",
    "    return np.column_stack(data)\n",
    "\n",
    "def objective(trial, df, target):\n",
    "    param = {        \n",
    "        'objective': 'reg:squarederror',        \n",
    "        'device' : 'cuda',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log = True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log = True),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.5, 0.7, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6, 0.8, 1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.05]),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 150, 300]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [2, 3, 5, 7, 9]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 100),\n",
    "        'early_stopping_rounds': 10  }\n",
    "    \n",
    "    mse_scores = []\n",
    "\n",
    "    for fold in df['fold'].unique():\n",
    "        train_data = df[df['fold'] != fold]\n",
    "        valid_data = df[df['fold'] == fold]\n",
    "\n",
    "        X_train = get_combined_data(train_data)\n",
    "        X_valid = get_combined_data(valid_data)\n",
    "\n",
    "        y_train = train_data[target]\n",
    "        y_valid = valid_data[target]\n",
    "\n",
    "    \n",
    "        model = xgb.XGBRegressor(**param)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "        preds = model.predict(X_valid)\n",
    "        mse = mean_squared_error(y_valid, preds)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    average_mse = np.mean(mse_scores)\n",
    "    return average_mse\n",
    "\n",
    "def optimize_model(df, target):\n",
    "\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, df, target), n_trials=15)\n",
    "    print(f'Optimization finished in {timedelta(seconds=time.time() - start_time)}')\n",
    "\n",
    "    best_params = study.best_trial.params    \n",
    "    if 'early_stopping_rounds' in best_params:\n",
    "        del best_params['early_stopping_rounds']\n",
    "    print(f\"Best parameters for {target}: \", best_params)\n",
    "    \n",
    "    # Käytä parhaita parametreja koko datan kouluttamiseen\n",
    "    X = get_combined_data(df)\n",
    "    y = df[target]\n",
    "    model = xgb.XGBRegressor(**best_params)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(row):\n",
    "    return np.array(row[f'model_features_423_std_powerlog_3_finetuned'])\n",
    "\n",
    "train_df['combined_features'] = train_df.apply(prepare_features, axis=1)\n",
    "# test_df['combined_features'] = test_df.apply(prepare_features, axis=1)\n",
    "testi['combined_features'] = testi.apply(prepare_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:34:14,149] A new study created in memory with name: no-name-7d0ecf96-8a8e-4ff6-aaa0-f54ae723be50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X4_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/miniconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:34:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1705650282415/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-04-25 17:34:47,186] Trial 0 finished with value: 0.014767306798050186 and parameters: {'lambda': 4.45328572879446e-06, 'alpha': 4.8413489204266845e-06, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 100, 'max_depth': 9, 'min_child_weight': 56}. Best is trial 0 with value: 0.014767306798050186.\n",
      "[I 2024-04-25 17:35:01,805] Trial 1 finished with value: 0.015395489288075163 and parameters: {'lambda': 0.00013050522763633686, 'alpha': 0.371704356841617, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 3, 'min_child_weight': 27}. Best is trial 0 with value: 0.014767306798050186.\n",
      "[I 2024-04-25 17:35:37,386] Trial 2 finished with value: 0.015818162167329782 and parameters: {'lambda': 0.003071991248201804, 'alpha': 7.026839136556473e-06, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 100, 'max_depth': 7, 'min_child_weight': 66}. Best is trial 0 with value: 0.014767306798050186.\n",
      "[I 2024-04-25 17:36:05,505] Trial 3 finished with value: 0.01590058280696329 and parameters: {'lambda': 1.873586215427018e-07, 'alpha': 0.00018812514676872289, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 200, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 0 with value: 0.014767306798050186.\n",
      "[I 2024-04-25 17:36:48,372] Trial 4 finished with value: 0.015033199435848668 and parameters: {'lambda': 0.1597272742833042, 'alpha': 8.024407512008387e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 76}. Best is trial 0 with value: 0.014767306798050186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:02:34.224883\n",
      "Best parameters for X4_mean:  {'lambda': 4.45328572879446e-06, 'alpha': 4.8413489204266845e-06, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 100, 'max_depth': 9, 'min_child_weight': 56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:37:15,979] A new study created in memory with name: no-name-b9bc0e33-3669-4dc1-90ed-99bc3758510f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X11_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:37:39,334] Trial 0 finished with value: 40.762398859222515 and parameters: {'lambda': 4.565401947671788e-05, 'alpha': 0.006463735410213292, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.01, 'n_estimators': 100, 'max_depth': 5, 'min_child_weight': 24}. Best is trial 0 with value: 40.762398859222515.\n",
      "[I 2024-04-25 17:39:04,457] Trial 1 finished with value: 38.19353471580814 and parameters: {'lambda': 4.4534597828663984e-07, 'alpha': 3.0359528699302198e-05, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 26}. Best is trial 1 with value: 38.19353471580814.\n",
      "[I 2024-04-25 17:39:34,340] Trial 2 finished with value: 37.931249293667484 and parameters: {'lambda': 1.3700545580176212e-08, 'alpha': 8.616392369610164e-08, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 5, 'min_child_weight': 24}. Best is trial 2 with value: 37.931249293667484.\n",
      "[I 2024-04-25 17:39:53,045] Trial 3 finished with value: 41.710856390634184 and parameters: {'lambda': 8.754859759542487e-08, 'alpha': 1.4699779593042377e-08, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 100, 'max_depth': 3, 'min_child_weight': 70}. Best is trial 2 with value: 37.931249293667484.\n",
      "[I 2024-04-25 17:40:09,278] Trial 4 finished with value: 40.2276424483048 and parameters: {'lambda': 2.1135727653652854e-07, 'alpha': 0.22434835388662747, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 3, 'min_child_weight': 85}. Best is trial 2 with value: 37.931249293667484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:02:53.300904\n",
      "Best parameters for X11_mean:  {'lambda': 1.3700545580176212e-08, 'alpha': 8.616392369610164e-08, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 5, 'min_child_weight': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:40:29,379] A new study created in memory with name: no-name-6204b0cf-3219-4e1c-a60e-ebea3d9b8daf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X18_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:41:20,448] Trial 0 finished with value: 15.035526680914359 and parameters: {'lambda': 0.15659445130096575, 'alpha': 0.002813637554420172, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 5, 'min_child_weight': 26}. Best is trial 0 with value: 15.035526680914359.\n",
      "[I 2024-04-25 17:42:38,800] Trial 1 finished with value: 14.684137451996055 and parameters: {'lambda': 0.031433276806015806, 'alpha': 0.14843686668481, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 17}. Best is trial 1 with value: 14.684137451996055.\n",
      "[I 2024-04-25 17:43:10,061] Trial 2 finished with value: 15.004700130950633 and parameters: {'lambda': 1.0538540518631162e-05, 'alpha': 9.643128339510929e-05, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 5, 'min_child_weight': 90}. Best is trial 1 with value: 14.684137451996055.\n",
      "[I 2024-04-25 17:43:58,077] Trial 3 finished with value: 14.947287259965302 and parameters: {'lambda': 1.1370479884296415e-06, 'alpha': 4.797188139829815e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 9, 'min_child_weight': 65}. Best is trial 1 with value: 14.684137451996055.\n",
      "[I 2024-04-25 17:44:22,275] Trial 4 finished with value: 15.546904392368438 and parameters: {'lambda': 2.505900764329288e-05, 'alpha': 0.41702807888710103, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 5, 'min_child_weight': 72}. Best is trial 1 with value: 14.684137451996055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:03:52.897955\n",
      "Best parameters for X18_mean:  {'lambda': 0.031433276806015806, 'alpha': 0.14843686668481, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:45:11,667] A new study created in memory with name: no-name-3fd4e05e-6e00-4c38-a356-ed8c549f7364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X50_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:46:34,638] Trial 0 finished with value: 0.2946775349542087 and parameters: {'lambda': 0.010456514269312772, 'alpha': 1.8387765258555765e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 64}. Best is trial 0 with value: 0.2946775349542087.\n",
      "[I 2024-04-25 17:46:59,739] Trial 1 finished with value: 0.2987816952910762 and parameters: {'lambda': 3.537941236501808e-05, 'alpha': 0.5346889894513339, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 150, 'max_depth': 5, 'min_child_weight': 32}. Best is trial 0 with value: 0.2946775349542087.\n",
      "[I 2024-04-25 17:47:21,377] Trial 2 finished with value: 0.31456508217408113 and parameters: {'lambda': 6.907886942057413e-07, 'alpha': 1.0102734924888815e-08, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.01, 'n_estimators': 150, 'max_depth': 3, 'min_child_weight': 87}. Best is trial 0 with value: 0.2946775349542087.\n",
      "[I 2024-04-25 17:47:49,758] Trial 3 finished with value: 0.3080019219418088 and parameters: {'lambda': 2.3202920772616845e-06, 'alpha': 0.9654579650054753, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 150, 'max_depth': 5, 'min_child_weight': 72}. Best is trial 0 with value: 0.2946775349542087.\n",
      "[I 2024-04-25 17:48:34,477] Trial 4 finished with value: 0.2941825299427217 and parameters: {'lambda': 0.0018940029791569275, 'alpha': 2.3886845476137073e-07, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 75}. Best is trial 4 with value: 0.2941825299427217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:03:22.811451\n",
      "Best parameters for X50_mean:  {'lambda': 0.0018940029791569275, 'alpha': 2.3886845476137073e-07, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.05, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:49:01,833] A new study created in memory with name: no-name-3923d791-9fb7-4303-8852-8d913d7adea8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X26_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:49:32,556] Trial 0 finished with value: 4530.0317574806995 and parameters: {'lambda': 1.2950622468904335e-08, 'alpha': 0.0001709665528726724, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 7, 'min_child_weight': 59}. Best is trial 0 with value: 4530.0317574806995.\n",
      "[I 2024-04-25 17:49:56,299] Trial 1 finished with value: 4507.48282272682 and parameters: {'lambda': 1.89937059558303e-08, 'alpha': 0.03826896768772912, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.05, 'n_estimators': 100, 'max_depth': 7, 'min_child_weight': 54}. Best is trial 1 with value: 4507.48282272682.\n",
      "[I 2024-04-25 17:50:24,884] Trial 2 finished with value: 4542.849951398067 and parameters: {'lambda': 0.0023916125469666907, 'alpha': 0.11270418176111754, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 7, 'min_child_weight': 46}. Best is trial 1 with value: 4507.48282272682.\n",
      "[I 2024-04-25 17:50:53,137] Trial 3 finished with value: 4665.138354476358 and parameters: {'lambda': 0.0011227792214643117, 'alpha': 0.00525852778249525, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 2, 'min_child_weight': 8}. Best is trial 1 with value: 4507.48282272682.\n",
      "[I 2024-04-25 17:51:40,398] Trial 4 finished with value: 4524.90495943411 and parameters: {'lambda': 0.03573846294218322, 'alpha': 1.6128788252112405e-05, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 5, 'min_child_weight': 48}. Best is trial 1 with value: 4507.48282272682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:02:38.566113\n",
      "Best parameters for X26_mean:  {'lambda': 1.89937059558303e-08, 'alpha': 0.03826896768772912, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.05, 'n_estimators': 100, 'max_depth': 7, 'min_child_weight': 54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:51:55,509] A new study created in memory with name: no-name-fecefb42-7d24-4b86-89f3-f7eaf1dccd56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X3112_mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 17:52:09,480] Trial 0 finished with value: 4038742.4890485955 and parameters: {'lambda': 0.011651712715905014, 'alpha': 1.9834579040302317e-08, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 2, 'min_child_weight': 80}. Best is trial 0 with value: 4038742.4890485955.\n",
      "[I 2024-04-25 17:53:01,823] Trial 1 finished with value: 3742098.718862331 and parameters: {'lambda': 0.28525264165915365, 'alpha': 1.8531908483751415e-06, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 58}. Best is trial 1 with value: 3742098.718862331.\n",
      "[I 2024-04-25 17:53:23,876] Trial 2 finished with value: 3850206.8316072794 and parameters: {'lambda': 0.0013324611247932676, 'alpha': 1.0604149868308294e-06, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 100, 'max_depth': 5, 'min_child_weight': 19}. Best is trial 1 with value: 3742098.718862331.\n",
      "[I 2024-04-25 17:54:00,165] Trial 3 finished with value: 3742321.282500282 and parameters: {'lambda': 0.011121860279411266, 'alpha': 0.4323450564507844, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 77}. Best is trial 1 with value: 3742098.718862331.\n",
      "[I 2024-04-25 17:55:27,967] Trial 4 finished with value: 3738953.250360894 and parameters: {'lambda': 0.02794196288107175, 'alpha': 1.363677972637457e-06, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 41}. Best is trial 4 with value: 3738953.250360894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished in 0:03:32.459077\n",
      "Best parameters for X3112_mean:  {'lambda': 0.02794196288107175, 'alpha': 1.363677972637457e-06, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 41}\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "\n",
    "# Mallien kouluttaminen jokaiselle kohdemuuttujalle\n",
    "models = {}\n",
    "for target in target_columns:    \n",
    "    print(f'\\n\\nOptimizing model for {target}\\n\\n')\n",
    "    models[target] = optimize_model(train_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.2211687070920861\n"
     ]
    }
   ],
   "source": [
    "features_array = np.array(testi['combined_features'].tolist())\n",
    "X_combined_train = np.hstack([testi[FEATURE_COLS].values, features_array])\n",
    "\n",
    "train_pred = np.zeros((testi.shape[0], len(target_columns)))\n",
    "\n",
    "for i, target in enumerate(target_columns):    \n",
    "    train_pred[:, i] = models[target].predict(X_combined_train)\n",
    "\n",
    "train_r2 = r2_score(testi[target_columns], train_pred)\n",
    "print(f'Training R2: {train_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting X4_mean with model XGBRegressor(alpha=4.8413489204266845e-06, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=4.45328572879446e-06,\n",
      "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
      "             max_leaves=None, min_child_weight=56, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "             n_jobs=None, ...)\n",
      "Predicting X11_mean with model XGBRegressor(alpha=8.616392369610164e-08, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.3, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=1.3700545580176212e-08,\n",
      "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "             max_leaves=None, min_child_weight=24, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "             n_jobs=None, ...)\n",
      "Predicting X18_mean with model XGBRegressor(alpha=0.14843686668481, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.031433276806015806,\n",
      "             learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=17, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=None, ...)\n",
      "Predicting X50_mean with model XGBRegressor(alpha=2.3886845476137073e-07, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.0018940029791569275,\n",
      "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=75, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "             n_jobs=None, ...)\n",
      "Predicting X26_mean with model XGBRegressor(alpha=0.03826896768772912, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=1.89937059558303e-08,\n",
      "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=54, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "             n_jobs=None, ...)\n",
      "Predicting X3112_mean with model XGBRegressor(alpha=1.363677972637457e-06, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.02794196288107175,\n",
      "             learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=41, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=None, ...)\n"
     ]
    }
   ],
   "source": [
    "features_array = np.array(testi['combined_features'].tolist())\n",
    "X_combined_test = np.hstack([testi[FEATURE_COLS].values, features_array])\n",
    "\n",
    "test_preds = np.zeros((len(testi), len(target_columns)))\n",
    "\n",
    "for i, target in enumerate(target_columns):\n",
    "    print(f'Predicting {target} with model {models[target]}')\n",
    "    test_preds[:, i] = models[target].predict(X_combined_test)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m target_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX11\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX18\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX26\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX3112\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m test_df_copy \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m test_df_copy[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m submission_df[target_columns] \u001b[38;5;241m=\u001b[39m test_preds\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "target_columns = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "submission_df = test_df_copy[['id']].copy()\n",
    "submission_df[target_columns] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[target_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
