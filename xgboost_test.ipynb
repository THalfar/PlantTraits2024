{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pd.read_csv('./data/test.csv')\n",
    "FEATURE_COLS = feat.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = '426_convnextbase_003_998_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = f'./data/test_{study_name}.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "\n",
    "pickle_file_path = f'./data/train_{study_name}.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_data(df):\n",
    "    # Oletetaan, että FEATURES_COLS on jo määritelty olemassa oleville piirteille\n",
    "    data = [df[col].values for col in FEATURE_COLS]\n",
    "    # Lisää mallin piirteet\n",
    "    data.append(np.vstack(df['combined_features'].values))\n",
    "    return np.column_stack(data)\n",
    "\n",
    "def objective(trial, df, target, fold_train, fold_validation):\n",
    "    param = {        \n",
    "        'objective': 'reg:squarederror',        \n",
    "        'device' : 'cuda',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log = True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log = True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.9),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 0.9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0,),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000, log = True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 100),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 5, 50)}\n",
    "    \n",
    "\n",
    "    train_data = df[df['fold'] == fold_train]\n",
    "    valid_data = df[df['fold'] == fold_validation]\n",
    "\n",
    "    X_train = get_combined_data(train_data)\n",
    "    X_valid = get_combined_data(valid_data)\n",
    "\n",
    "    y_train = train_data[target]\n",
    "    y_valid = valid_data[target]\n",
    "\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "    preds = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, preds)\n",
    "\n",
    "    return mse\n",
    "\n",
    "def optimize_model(df, target, fold_train, fold_validation):\n",
    "\n",
    "    if os.path.exists(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_genesampler.pickle'):            \n",
    "        with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_genesampler.pickle', 'rb') as f:\n",
    "            print(f'Loading gene sampler from file {f}')\n",
    "            genemachine = pickle.load(f)\n",
    "\n",
    "    else:            \n",
    "        print('Creating new gene sampler')\n",
    "        genemachine = optuna.samplers.NSGAIISampler(crossover = optuna.samplers.nsgaii.VSBXCrossover())\n",
    "\n",
    "    if os.path.exists(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_qmc_sampler.pickle'):\n",
    "        with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_qmc_sampler.pickle', 'rb') as f:\n",
    "            print(f'Loading QMC sampler from file {f}')\n",
    "            qmc_sampler = pickle.load(f)\n",
    "    else:\n",
    "        print(f'Creating new QMC sampler')\n",
    "        qmc_sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False)\n",
    "\n",
    "    if os.path.exists(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_tpe_sampler.pickle'):\n",
    "        with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_tpe_sampler.pickle', 'rb') as f:\n",
    "            print(f'Loading TPE sampler from file {f}')\n",
    "            tpe_sampler = pickle.load(f)\n",
    "    else:\n",
    "        print(f'Creating new TPE sampler')\n",
    "        tpe_sampler = optuna.samplers.TPESampler(n_startup_trials=0, multivariate=True, warn_independent_sampling = False)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(direction='minimize',\n",
    "                            study_name=study_name,\n",
    "                            storage=f'sqlite:///427_xgboost_{target}.db',\n",
    "                            load_if_exists=True                            \n",
    "                            )\n",
    "    \n",
    "    print(f'Starting optimization for {target} with qmc sampler')\n",
    "    random_time = time.time()\n",
    "    study.sampler = qmc_sampler\n",
    "    study.optimize(lambda trial: objective(trial, df, target, fold_train, fold_validation), n_trials=42)\n",
    "    print(f'QCM optimization finished in {timedelta(seconds=time.time() - random_time)}')\n",
    "\n",
    "    print(f'Saving QMC sampler to file ./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_qmc_sampler.pickle')\n",
    "    with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_qmc_sampler.pickle', 'wb') as f:\n",
    "        pickle.dump(qmc_sampler, f)\n",
    "\n",
    "    print(f'Starting optimization for {target} with gene sampler')\n",
    "    gene_time = time.time()\n",
    "    study.sampler = genemachine\n",
    "    study.optimize(lambda trial: objective(trial, df, target, fold_train, fold_validation), n_trials=42)\n",
    "    print(f'Gene optimization finished in {timedelta(seconds=time.time() - gene_time)}')\n",
    "\n",
    "    print(f'Saving gene sampler to file ./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_genesampler.pickle')\n",
    "    with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_genesampler.pickle', 'wb') as f:\n",
    "        pickle.dump(genemachine, f)\n",
    "\n",
    "    print(f'Starting optimization for {target} with TPE sampler')\n",
    "    tpe_time = time.time()\n",
    "    study.sampler = tpe_sampler\n",
    "    study.optimize(lambda trial: objective(trial, df, target, fold_train, fold_validation), n_trials=42)\n",
    "    print(f'TPE optimization finished in {timedelta(seconds=time.time() - tpe_time)}')\n",
    "\n",
    "    print(f'Saving TPE sampler to file ./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_tpe_sampler.pickle')\n",
    "    with open(f'./NN_search/{study_name}_{fold_train}_{fold_validation}_{target}_tpe_sampler.pickle', 'wb') as f:\n",
    "        pickle.dump(tpe_sampler, f)\n",
    "\n",
    "    print(f'Optimization finished in {timedelta(seconds=time.time() - start_time)}')\n",
    "\n",
    "    best_params = study.best_trial.params    \n",
    "\n",
    "    mse_scores = []\n",
    "\n",
    "    for fold in df['fold'].unique():\n",
    "        train_data = df[df['fold'] != fold]\n",
    "        valid_data = df[df['fold'] == fold]\n",
    "\n",
    "        X_train = get_combined_data(train_data)\n",
    "        X_valid = get_combined_data(valid_data)\n",
    "\n",
    "        y_train = train_data[target]\n",
    "        y_valid = valid_data[target]\n",
    "\n",
    "    \n",
    "        model = xgb.XGBRegressor(**best_params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "        preds = model.predict(X_valid)\n",
    "        mse = mean_squared_error(y_valid, preds)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    average_mse = np.mean(mse_scores)\n",
    "\n",
    "    print(f'Cross-validated MSE: {average_mse} for {target}')\n",
    "\n",
    "    if 'early_stopping_rounds' in best_params:\n",
    "        del best_params['early_stopping_rounds']\n",
    "    print(f\"Best parameters for {target}: \", best_params)\n",
    "\n",
    "    print(f'Fitting model for {target} with best parameters')\n",
    "    \n",
    "    # Käytä parhaita parametreja koko datan kouluttamiseen\n",
    "    X = get_combined_data(df)\n",
    "    y = df[target]\n",
    "    model = xgb.XGBRegressor(**best_params)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n",
       "      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n",
       "      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n",
       "      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n",
       "      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>bin_5</th>\n",
       "      <th>final_bin</th>\n",
       "      <th>fold</th>\n",
       "      <th>features_avg</th>\n",
       "      <th>model_features_426_convnextbase_003_998_1_finetuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192027691</td>\n",
       "      <td>12.235703</td>\n",
       "      <td>374.466675</td>\n",
       "      <td>62.524445</td>\n",
       "      <td>72.256844</td>\n",
       "      <td>773.592041</td>\n",
       "      <td>33.277779</td>\n",
       "      <td>125</td>\n",
       "      <td>149</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>221421</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.14304829, -0.28004962, 0.886131, -0.183084...</td>\n",
       "      <td>[-0.3265194594860077, -0.5460191965103149, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195542235</td>\n",
       "      <td>17.270555</td>\n",
       "      <td>90.239998</td>\n",
       "      <td>10.351111</td>\n",
       "      <td>38.220940</td>\n",
       "      <td>859.193298</td>\n",
       "      <td>40.009777</td>\n",
       "      <td>124</td>\n",
       "      <td>144</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>332223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.16563013, -1.4509088, 0.46862665, 0.2771467...</td>\n",
       "      <td>[0.009429454803466797, -0.5460116267204285, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196639184</td>\n",
       "      <td>14.254504</td>\n",
       "      <td>902.071411</td>\n",
       "      <td>49.642857</td>\n",
       "      <td>17.873655</td>\n",
       "      <td>387.977753</td>\n",
       "      <td>22.807142</td>\n",
       "      <td>107</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>515523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.034171782, -0.13625506, 0.5971655, -0.6490...</td>\n",
       "      <td>[-0.1011316254734993, -0.5460186004638672, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195728812</td>\n",
       "      <td>18.680834</td>\n",
       "      <td>1473.933350</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>45.009758</td>\n",
       "      <td>381.053986</td>\n",
       "      <td>20.436666</td>\n",
       "      <td>120</td>\n",
       "      <td>131</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>323213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.881118, -0.16722384, 1.3514438, 0.34779415...</td>\n",
       "      <td>[1.4968960285186768, -0.5460196137428284, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195251545</td>\n",
       "      <td>0.673204</td>\n",
       "      <td>530.088867</td>\n",
       "      <td>50.857777</td>\n",
       "      <td>38.230709</td>\n",
       "      <td>1323.526855</td>\n",
       "      <td>45.891998</td>\n",
       "      <td>91</td>\n",
       "      <td>146</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>233544</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[-0.3382826, 0.3086146, 0.58881557, 0.24890125...</td>\n",
       "      <td>[-0.3912062346935272, -0.5460014343261719, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  WORLDCLIM_BIO1_annual_mean_temperature  \\\n",
       "0  192027691                               12.235703   \n",
       "1  195542235                               17.270555   \n",
       "2  196639184                               14.254504   \n",
       "3  195728812                               18.680834   \n",
       "4  195251545                                0.673204   \n",
       "\n",
       "   WORLDCLIM_BIO12_annual_precipitation  \\\n",
       "0                            374.466675   \n",
       "1                             90.239998   \n",
       "2                            902.071411   \n",
       "3                           1473.933350   \n",
       "4                            530.088867   \n",
       "\n",
       "   WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n",
       "0                                          62.524445                       \n",
       "1                                          10.351111                       \n",
       "2                                          49.642857                       \n",
       "3                                         163.100006                       \n",
       "4                                          50.857777                       \n",
       "\n",
       "   WORLDCLIM_BIO15_precipitation_seasonality  \\\n",
       "0                                  72.256844   \n",
       "1                                  38.220940   \n",
       "2                                  17.873655   \n",
       "3                                  45.009758   \n",
       "4                                  38.230709   \n",
       "\n",
       "   WORLDCLIM_BIO4_temperature_seasonality  \\\n",
       "0                              773.592041   \n",
       "1                              859.193298   \n",
       "2                              387.977753   \n",
       "3                              381.053986   \n",
       "4                             1323.526855   \n",
       "\n",
       "   WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n",
       "0                                33.277779                            125   \n",
       "1                                40.009777                            124   \n",
       "2                                22.807142                            107   \n",
       "3                                20.436666                            120   \n",
       "4                                45.891998                             91   \n",
       "\n",
       "   SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  ...  \\\n",
       "0                                149                              136  ...   \n",
       "1                                144                              138  ...   \n",
       "2                                133                              119  ...   \n",
       "3                                131                              125  ...   \n",
       "4                                146                              120  ...   \n",
       "\n",
       "   bin_0  bin_1  bin_2  bin_3  bin_4  bin_5  final_bin  fold  \\\n",
       "0      2      2      1      4      2      1     221421   2.0   \n",
       "1      3      3      2      2      2      3     332223   4.0   \n",
       "2      5      1      5      5      2      3     515523   2.0   \n",
       "3      3      2      3      2      1      3     323213   0.0   \n",
       "4      2      3      3      5      4      4     233544   4.0   \n",
       "\n",
       "                                        features_avg  \\\n",
       "0  [-0.14304829, -0.28004962, 0.886131, -0.183084...   \n",
       "1  [0.16563013, -1.4509088, 0.46862665, 0.2771467...   \n",
       "2  [-0.034171782, -0.13625506, 0.5971655, -0.6490...   \n",
       "3  [-0.881118, -0.16722384, 1.3514438, 0.34779415...   \n",
       "4  [-0.3382826, 0.3086146, 0.58881557, 0.24890125...   \n",
       "\n",
       "   model_features_426_convnextbase_003_998_1_finetuned  \n",
       "0  [-0.3265194594860077, -0.5460191965103149, -0....    \n",
       "1  [0.009429454803466797, -0.5460116267204285, -0...    \n",
       "2  [-0.1011316254734993, -0.5460186004638672, -0....    \n",
       "3  [1.4968960285186768, -0.5460196137428284, -0.5...    \n",
       "4  [-0.3912062346935272, -0.5460014343261719, -0....    \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(row):\n",
    "    return np.array(row[f'model_features_{study_name}_finetuned'])\n",
    "\n",
    "train_df['combined_features'] = train_df.apply(prepare_features, axis=1)\n",
    "test_df['combined_features'] = test_df.apply(prepare_features, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizing model for X4_mean using train fold 1 and validation fold 2\n",
      "\n",
      "\n",
      "Creating new gene sampler\n",
      "Creating new QMC sampler\n",
      "Creating new TPE sampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3655715/1750598810.py:48: ExperimentalWarning: VSBXCrossover is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  genemachine = optuna.samplers.NSGAIISampler(crossover = optuna.samplers.nsgaii.VSBXCrossover())\n",
      "/tmp/ipykernel_3655715/1750598810.py:56: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  qmc_sampler = optuna.samplers.QMCSampler(warn_independent_sampling = False)\n",
      "/home/tobias/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-04-27 23:19:08,587] A new study created in RDB with name: 426_convnextbase_003_998_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for X4_mean with qmc sampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/miniconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [23:19:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1705650282415/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-04-27 23:19:12,092] Trial 0 finished with value: 0.0072839706961062775 and parameters: {'lambda': 6.037116720945384e-07, 'alpha': 0.012774407106202087, 'colsample_bytree': 0.20788578187445517, 'subsample': 0.3601674899569792, 'learning_rate': 0.3784249525690579, 'n_estimators': 372, 'max_depth': 14, 'min_child_weight': 86, 'early_stopping_rounds': 8}. Best is trial 0 with value: 0.0072839706961062775.\n",
      "[I 2024-04-27 23:19:12,898] Trial 1 finished with value: 0.02000475225854336 and parameters: {'lambda': 0.0003018464988063167, 'alpha': 0.03317359338443019, 'colsample_bytree': 0.1, 'subsample': 0.1, 'learning_rate': 0.01, 'n_estimators': 10, 'max_depth': 2, 'min_child_weight': 1, 'early_stopping_rounds': 5}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:15,011] Trial 2 finished with value: 0.007691862981210373 and parameters: {'lambda': 9.999999999999991e-05, 'alpha': 9.999999999999991e-05, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.505, 'n_estimators': 97, 'max_depth': 11, 'min_child_weight': 51, 'early_stopping_rounds': 27}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:15,923] Trial 3 finished with value: 0.00822788641550118 and parameters: {'lambda': 0.009999999999999995, 'alpha': 9.999999999999987e-07, 'colsample_bytree': 0.30000000000000004, 'subsample': 0.30000000000000004, 'learning_rate': 0.7525, 'n_estimators': 312, 'max_depth': 6, 'min_child_weight': 75, 'early_stopping_rounds': 39}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:20,710] Trial 4 finished with value: 0.007236878782160666 and parameters: {'lambda': 9.999999999999987e-07, 'alpha': 0.009999999999999995, 'colsample_bytree': 0.7000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.2575, 'n_estimators': 30, 'max_depth': 16, 'min_child_weight': 25, 'early_stopping_rounds': 16}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:22,173] Trial 5 finished with value: 0.006787371097414139 and parameters: {'lambda': 9.99999999999998e-06, 'alpha': 9.99999999999998e-06, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.38125, 'n_estimators': 17, 'max_depth': 9, 'min_child_weight': 88, 'early_stopping_rounds': 45}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:23,607] Trial 6 finished with value: 0.009515535390804082 and parameters: {'lambda': 0.0999999999999999, 'alpha': 0.0999999999999999, 'colsample_bytree': 0.2, 'subsample': 0.4, 'learning_rate': 0.87625, 'n_estimators': 174, 'max_depth': 18, 'min_child_weight': 38, 'early_stopping_rounds': 22}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:24,133] Trial 7 finished with value: 0.007392306994504911 and parameters: {'lambda': 0.0010000000000000002, 'alpha': 9.999999999999994e-08, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.62875, 'n_estimators': 559, 'max_depth': 4, 'min_child_weight': 13, 'early_stopping_rounds': 10}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:25,341] Trial 8 finished with value: 0.00678088561892922 and parameters: {'lambda': 9.999999999999994e-08, 'alpha': 0.0010000000000000002, 'colsample_bytree': 0.4, 'subsample': 0.2, 'learning_rate': 0.13375, 'n_estimators': 54, 'max_depth': 13, 'min_child_weight': 63, 'early_stopping_rounds': 33}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:26,626] Trial 9 finished with value: 0.007688775966798786 and parameters: {'lambda': 3.1622776601683734e-07, 'alpha': 3.162277660168377e-06, 'colsample_bytree': 0.85, 'subsample': 0.45000000000000007, 'learning_rate': 0.566875, 'n_estimators': 41, 'max_depth': 10, 'min_child_weight': 94, 'early_stopping_rounds': 48}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:31,720] Trial 10 finished with value: 0.006139654625830725 and parameters: {'lambda': 0.0031622776601683764, 'alpha': 0.0316227766016838, 'colsample_bytree': 0.45000000000000007, 'subsample': 0.85, 'learning_rate': 0.071875, 'n_estimators': 418, 'max_depth': 19, 'min_child_weight': 44, 'early_stopping_rounds': 25}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:32,534] Trial 11 finished with value: 0.007196394556930228 and parameters: {'lambda': 0.31622776601683833, 'alpha': 3.16227766016837e-08, 'colsample_bytree': 0.65, 'subsample': 0.25, 'learning_rate': 0.319375, 'n_estimators': 130, 'max_depth': 5, 'min_child_weight': 19, 'early_stopping_rounds': 13}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:33,527] Trial 12 finished with value: 0.008410065690308857 and parameters: {'lambda': 3.162277660168375e-05, 'alpha': 0.00031622776601683783, 'colsample_bytree': 0.25, 'subsample': 0.65, 'learning_rate': 0.814375, 'n_estimators': 13, 'max_depth': 15, 'min_child_weight': 69, 'early_stopping_rounds': 36}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:34,019] Trial 13 finished with value: 0.007939363033907628 and parameters: {'lambda': 3.162277660168377e-06, 'alpha': 3.1622776601683734e-07, 'colsample_bytree': 0.35, 'subsample': 0.55, 'learning_rate': 0.938125, 'n_estimators': 73, 'max_depth': 3, 'min_child_weight': 7, 'early_stopping_rounds': 7}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:35,072] Trial 14 finished with value: 0.008182507394664026 and parameters: {'lambda': 0.0316227766016838, 'alpha': 0.0031622776601683764, 'colsample_bytree': 0.75, 'subsample': 0.15000000000000002, 'learning_rate': 0.443125, 'n_estimators': 748, 'max_depth': 12, 'min_child_weight': 57, 'early_stopping_rounds': 30}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:36,497] Trial 15 finished with value: 0.006408628650169343 and parameters: {'lambda': 0.00031622776601683783, 'alpha': 3.162277660168375e-05, 'colsample_bytree': 0.15000000000000002, 'subsample': 0.75, 'learning_rate': 0.195625, 'n_estimators': 233, 'max_depth': 7, 'min_child_weight': 82, 'early_stopping_rounds': 42}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:37,779] Trial 16 finished with value: 0.008705157499991279 and parameters: {'lambda': 3.16227766016837e-08, 'alpha': 0.31622776601683833, 'colsample_bytree': 0.55, 'subsample': 0.35, 'learning_rate': 0.690625, 'n_estimators': 23, 'max_depth': 17, 'min_child_weight': 32, 'early_stopping_rounds': 19}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:39,149] Trial 17 finished with value: 0.006714584738051218 and parameters: {'lambda': 5.6234132519034806e-08, 'alpha': 5.6234132519034893e-05, 'colsample_bytree': 0.475, 'subsample': 0.625, 'learning_rate': 0.2884375, 'n_estimators': 865, 'max_depth': 12, 'min_child_weight': 85, 'early_stopping_rounds': 26}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:40,116] Trial 18 finished with value: 0.007704902975834925 and parameters: {'lambda': 0.0005623413251903486, 'alpha': 0.5623413251903484, 'colsample_bytree': 0.875, 'subsample': 0.225, 'learning_rate': 0.7834375, 'n_estimators': 84, 'max_depth': 2, 'min_child_weight': 35, 'early_stopping_rounds': 49}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:19:55,988] Trial 19 finished with value: 0.009589290350607866 and parameters: {'lambda': 0.056234132519034884, 'alpha': 5.623413251903487e-07, 'colsample_bytree': 0.275, 'subsample': 0.8250000000000001, 'learning_rate': 0.5359375, 'n_estimators': 26, 'max_depth': 16, 'min_child_weight': 10, 'early_stopping_rounds': 38}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:20:04,446] Trial 20 finished with value: 0.006105841800430124 and parameters: {'lambda': 5.623413251903483e-06, 'alpha': 0.005623413251903492, 'colsample_bytree': 0.675, 'subsample': 0.42500000000000004, 'learning_rate': 0.0409375, 'n_estimators': 270, 'max_depth': 7, 'min_child_weight': 60, 'early_stopping_rounds': 15}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:20:07,482] Trial 21 finished with value: 0.007356991178614218 and parameters: {'lambda': 5.6234132519034893e-05, 'alpha': 5.6234132519034806e-08, 'colsample_bytree': 0.775, 'subsample': 0.325, 'learning_rate': 0.16468750000000001, 'n_estimators': 483, 'max_depth': 19, 'min_child_weight': 22, 'early_stopping_rounds': 32}. Best is trial 1 with value: 0.02000475225854336.\n",
      "[I 2024-04-27 23:20:09,542] Trial 22 finished with value: 0.007583372262224946 and parameters: {'lambda': 0.5623413251903484, 'alpha': 0.0005623413251903486, 'colsample_bytree': 0.375, 'subsample': 0.725, 'learning_rate': 0.6596875, 'n_estimators': 47, 'max_depth': 9, 'min_child_weight': 72, 'early_stopping_rounds': 9}. Best is trial 1 with value: 0.02000475225854336.\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "train_fold = 1\n",
    "validation_fold = 2\n",
    "\n",
    "# Mallien kouluttaminen jokaiselle kohdemuuttujalle\n",
    "models = {}\n",
    "\n",
    "time_search_start = time.time()\n",
    "time_taken = 0\n",
    "\n",
    "while time_taken < 3600 * 8:\n",
    "    for target in target_columns:    \n",
    "        print(f'\\n\\nOptimizing model for {target} using train fold {train_fold} and validation fold {validation_fold}\\n\\n')\n",
    "        models[target] = optimize_model(train_df, target, train_fold, validation_fold)\n",
    "        time_taken = time.time() - time_search_start\n",
    "        print(f'Time taken: {timedelta(seconds=time_taken)}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(train_df['combined_features'].tolist())\n",
    "X_combined_train = np.hstack([train_df[FEATURE_COLS].values, features_array])\n",
    "\n",
    "train_pred = np.zeros((train_df.shape[0], len(target_columns)))\n",
    "\n",
    "for i, target in enumerate(target_columns):    \n",
    "    train_pred[:, i] = models[target].predict(X_combined_train)\n",
    "\n",
    "train_r2 = r2_score(df[target_columns], train_pred)\n",
    "print(f'Training R2: {train_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(test_df['combined_features'].tolist())\n",
    "X_combined_test = np.hstack([test_df[FEATURE_COLS].values, features_array])\n",
    "\n",
    "test_preds = np.zeros((len(test_df), len(target_columns)))\n",
    "\n",
    "for i, target in enumerate(target_columns):\n",
    "    print(f'Predicting {target} with model {models[target]}')\n",
    "    test_preds[:, i] = models[target].predict(X_combined_test)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "submission_df = test_df_copy[['id']].copy()\n",
    "submission_df[target_columns] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[target_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
