{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,  RobustScaler\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2M\n",
    "import numpy as np\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "mean_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "FEATURE_COLS = test_df.columns[1:].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_columns = [col for col in train_df.columns if col.endswith('_sd')]\n",
    "train_df.drop(columns=sd_columns, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images_path = './data/train_images/'\n",
    "test_images_path = './data/test_images/'    \n",
    "\n",
    "train_df['image_path'] = train_df['id'].apply(lambda x: os.path.join(train_images_path, f'{x}.jpeg'))\n",
    "test_df['image_path'] = test_df['id'].apply(lambda x: os.path.join(test_images_path, f'{x}.jpeg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_data(df, columns_names):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "\n",
    "    # Setting up a grid of plots with 2 columns\n",
    "    n_cols = 6\n",
    "    n_rows = len(columns_names) // n_cols + (len(columns_names) % n_cols > 0)\n",
    "\n",
    "    for i, col in enumerate(columns_names):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        sns.kdeplot(df[col], bw_adjust=0.5, fill=False, color='blue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Density')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[mean_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(train_df, mean_columns)\n",
    "\n",
    "for column in mean_columns:\n",
    "    lower_quantile = train_df[column].quantile(0.003)\n",
    "    upper_quantile = train_df[column].quantile(0.995)  \n",
    "    train_df = train_df[(train_df[column] >= lower_quantile) & (train_df[column] <= upper_quantile)]\n",
    "    \n",
    "\n",
    "plot_data(train_df, mean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[mean_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, trait in enumerate(mean_columns):\n",
    "\n",
    "    # Determine the bin edges dynamically based on the distribution of traits\n",
    "    bin_edges = np.percentile(train_df[trait], np.linspace(0, 100, 5 + 1))\n",
    "    train_df[f\"bin_{i}\"] = np.digitize(train_df[trait], bin_edges)\n",
    "\n",
    "# Concatenate the bins into a final bin\n",
    "train_df[\"final_bin\"] = (\n",
    "    train_df[[f\"bin_{i}\" for i in range(len(mean_columns))]]\n",
    "    .astype(str)\n",
    "    .agg(\"\".join, axis=1)\n",
    ")\n",
    "\n",
    "# Perform the stratified split using final bin\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df, train_df[\"final_bin\"])):\n",
    "    train_df.loc[valid_idx, \"fold\"] = fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.head())\n",
    "print(train_df.describe())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file path to save the pickle file\n",
    "pickle_file_path = './data/train_df_uusi.pickle'\n",
    "\n",
    "# Save the train_df dataframe as a pickle file\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = './data/test_df_uusi.pickle'\n",
    "\n",
    "# # Save the train_df dataframe as a pickle file\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(test_df, f)\n",
    "\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
