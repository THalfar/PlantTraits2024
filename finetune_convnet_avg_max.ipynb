{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:25:36.493196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-20 13:25:37.089221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.1\n",
      "Current GPU allocator: cuda_malloc_async\n",
      "Setting memory growth for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2024-05-20 13:25:37.613513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:37.631559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:37.631679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,  RobustScaler\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from keras import regularizers, layers, optimizers, initializers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, Lambda, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetV2M, ConvNeXtBase, ConvNeXtLarge\n",
    "\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    " \n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "print(f'Current GPU allocator: {os.getenv(\"TF_GPU_ALLOCATOR\")}')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            print(f'Setting memory growth for {gpu}')\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = '518_convnextlarge_maxavg_Jkl_kunpaeikamalaolo_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Aseta näyttämään rajoittamaton määrä sarakkeita\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_file_path = './data/test_df.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "\n",
    "pickle_file_path = './data/train_df.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TESTING IMAGE AUGEMENTATION\n",
    "# train_df = train_df.sample(1000)\n",
    "# test_df = test_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pd.read_csv('./data/test.csv')\n",
    "FEATURE_COLS = feat.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Num Train: 43088 | Num Valid: 10772\n"
     ]
    }
   ],
   "source": [
    "scaler_feat = RobustScaler()\n",
    "\n",
    "train_original = train_df.copy()\n",
    "train_plot = train_df.copy()\n",
    "sample_df = train_df.copy()\n",
    "\n",
    "train_df = sample_df[sample_df.fold != 2]\n",
    "valid_df = sample_df[sample_df.fold == 2]\n",
    "\n",
    "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2-score: 0.42463\n",
      "Best model: ./NN_search/518_convnextlarge_maxavg_Jkl_kunpaeikamalaolo_2_best_val_0.42463_model.h5\n",
      "Opening log transforms from ./NN_search/518_convnextlarge_maxavg_Jkl_kunpaeikamalaolo_2_0.42463_best_log_transforms.pickle\n",
      "Opening scalers from ./NN_search/518_convnextlarge_maxavg_Jkl_kunpaeikamalaolo_2_0.42463_best_scalers.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:25:40.927422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:40.927545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:40.927600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:41.034030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:41.034116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:41.034125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-20 13:25:41.034181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 13:25:41.034222: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-05-20 13:25:41.034377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_avg_input (InputLayer)   [(None, 1536)]       0           []                               \n",
      "                                                                                                  \n",
      " image_max_input (InputLayer)   [(None, 1536)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5922)         9102114     ['image_avg_input[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 348)          534876      ['image_max_input[0][0]']        \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 5922)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 348)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5922)         0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 348)          0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3086)         18278378    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 45)           15705       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 3086)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 45)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3086)         0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 45)           0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3086)        12344       ['dropout_1[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3131)         0           ['dropout_3[0][0]',              \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 241)          754812      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 241)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 241)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 148)          35816       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 148)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 148)          0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 148)         592         ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 6)            894         ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,735,531\n",
      "Trainable params: 28,729,063\n",
      "Non-trainable params: 6,468\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "directory_path = './NN_search'\n",
    "pattern = f\"{directory_path}/{study_name}*.h5\"\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "max_r2_score = float('-inf')\n",
    "best_model = None\n",
    "\n",
    "# Käy läpi jokainen tiedosto ja etsi suurin r2_score_inv\n",
    "for file in files:\n",
    "    value = float(file.split('best_val')[1].split('_')[1])\n",
    "    if value > max_r2_score:\n",
    "        max_r2_score = value\n",
    "        best_model = file\n",
    "\n",
    "\n",
    "# Tulosta suurin löydetty r2_score_inv ja vastaava tiedosto\n",
    "print(f\"Best R2-score: {max_r2_score:.5f}\")\n",
    "if best_model:\n",
    "    print(f\"Best model: {best_model}\")\n",
    "else:\n",
    "    print(\"No best model found\")\n",
    "\n",
    "best_log_transforms_name =  f'./NN_search/{study_name}_{max_r2_score:.5f}_best_log_transforms.pickle'\n",
    "best_scalers_name = f'./NN_search/{study_name}_{max_r2_score:.5f}_best_scalers.pickle'\n",
    "\n",
    "print(f'Opening log transforms from {best_log_transforms_name}')\n",
    "with open(best_log_transforms_name, 'rb') as f:\n",
    "    log_transforms = pickle.load(f)\n",
    "\n",
    "print(f'Opening scalers from {best_scalers_name}')\n",
    "with open(best_scalers_name, 'rb') as f:\n",
    "    scaler_transforms = pickle.load(f)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "\n",
    "def r2_score_tf(y_true, y_pred):\n",
    "\n",
    "    try: \n",
    "        ss_res = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "        ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true, axis=0)), axis=0)\n",
    "        r2 = 1 - ss_res/(ss_tot + tf.keras.backend.epsilon())\n",
    "        r2 = tf.where(tf.math.is_nan(r2), tf.zeros_like(r2), r2) \n",
    "        return tf.reduce_mean(tf.maximum(r2, 0.0))\n",
    "    except Exception as e:\n",
    "        # print(f'Error in r2_score_tf: {e}')\n",
    "        return float('-inf')\n",
    "    \n",
    "custom_objects = {\n",
    "    'r2_score_tf': r2_score_tf\n",
    "    \n",
    "}\n",
    "nas_model  = tf.keras.models.load_model(best_model, custom_objects=custom_objects)\n",
    "\n",
    "nas_model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_features = nas_model.layers[-2].output\n",
    "nas_features = Model(inputs=nas_model.input, outputs=nas_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in nas_features.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_avg_input (InputLayer)   [(None, 1536)]       0           []                               \n",
      "                                                                                                  \n",
      " image_max_input (InputLayer)   [(None, 1536)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5922)         9102114     ['image_avg_input[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 348)          534876      ['image_max_input[0][0]']        \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 5922)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 348)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5922)         0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 348)          0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3086)         18278378    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 45)           15705       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 3086)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 45)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3086)         0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 45)           0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3086)        12344       ['dropout_1[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3131)         0           ['dropout_3[0][0]',              \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 241)          754812      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 241)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 241)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 148)          35816       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 148)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 148)          0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 148)         592         ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,734,637\n",
      "Trainable params: 28,728,169\n",
      "Non-trainable params: 6,468\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nas_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters nas: 28,735,531\n",
      "Trainable parameters nas: 28,729,063\n",
      "Non-trainable parameters nas: 6,468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainable_count_nas = sum([tf.size(v).numpy() for v in nas_model.trainable_weights])\n",
    "non_trainable_count_nas = sum([tf.size(v).numpy() for v in nas_model.non_trainable_weights])\n",
    "print(f\"Total parameters nas: {trainable_count_nas + non_trainable_count_nas:,}\")\n",
    "print(f\"Trainable parameters nas: {trainable_count_nas:,}\")\n",
    "print(f\"Non-trainable parameters nas: {non_trainable_count_nas:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler are: StandardScaler()\n",
      "Log transforms are: {'X4_mean': 2, 'X11_mean': 13, 'X18_mean': 11, 'X50_mean': 3, 'X26_mean': 9, 'X3112_mean': 2}\n"
     ]
    }
   ],
   "source": [
    "print(f'Scaler are: {scaler_transforms}')\n",
    "print(f'Log transforms are: {log_transforms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_erasing(img, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, method = 'random'):\n",
    "    #Motivated by https://github.com/Amitayus/Random-Erasing-TensorFlow.git\n",
    "    #Motivated by https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\n",
    "    '''\n",
    "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    img : 3D Tensor data (H,W,Channels) normalized value [0,1]\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio\n",
    "    method : 'black', 'white' or 'random'. Erasing type\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    methods = ['random', 'white', 'black']\n",
    "    method = tf.random.shuffle(methods)[0].numpy().decode('utf-8')\n",
    "\n",
    "    if tf.random.uniform([]) > probability:\n",
    "        return img\n",
    "\n",
    "    img_width    = img.shape[1]\n",
    "    img_height   = img.shape[0]\n",
    "    img_channels = img.shape[2]\n",
    "\n",
    "    area = img_height * img_width\n",
    "\n",
    "    target_area = tf.random.uniform([],minval=sl, maxval=sh) * area\n",
    "    aspect_ratio = tf.random.uniform([],minval=r1, maxval=1/r1)\n",
    "    h = tf.cast(tf.math.round(tf.math.sqrt(target_area * aspect_ratio)), tf.int32)\n",
    "    w = tf.cast(tf.math.round(tf.math.sqrt(target_area / aspect_ratio)), tf.int32)\n",
    "\n",
    "    while tf.constant(True, dtype=tf.bool):\n",
    "        if h > img_height or w > img_width:\n",
    "            target_area = tf.random.uniform([],minval=sl, maxval=sh) * area\n",
    "            aspect_ratio = tf.random.uniform([],minval=r1, maxval=1/r1)\n",
    "            h = tf.cast(tf.math.round(tf.math.sqrt(target_area * aspect_ratio)), tf.int32)\n",
    "            w = tf.cast(tf.math.round(tf.math.sqrt(target_area / aspect_ratio)), tf.int32)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    x1 = tf.cond(img_height == h, lambda:0, lambda:tf.random.uniform([], minval=0, maxval=img_height - h, dtype=tf.int32))\n",
    "    y1 = tf.cond(img_width  == w, lambda:0, lambda:tf.random.uniform([], minval=0, maxval=img_width - w, dtype=tf.int32))\n",
    "    \n",
    "    part1 = tf.slice(img, [0,0,0], [x1,img_width,img_channels]) # first row\n",
    "    part2 = tf.slice(img, [x1,0,0], [h,y1,img_channels]) # second row 1\n",
    "\n",
    "    if method == 'black':\n",
    "        part3 = tf.zeros((h,w,img_channels), dtype=tf.float32) # second row 2\n",
    "    elif method == 'white':\n",
    "        part3 = tf.ones((h,w,img_channels), dtype=tf.float32)\n",
    "    elif method == 'random':\n",
    "        part3 = tf.random.uniform((h,w,img_channels), dtype=tf.float32)\n",
    "    \n",
    "    part4 = tf.slice(img,[x1,y1+w,0], [h,img_width-y1-w,img_channels]) # second row 3\n",
    "    part5 = tf.slice(img,[x1+h,0,0], [img_height-x1-h,img_width,img_channels]) # third row\n",
    "\n",
    "    middle_row = tf.concat([part2,part3,part4], axis=1)\n",
    "    img = tf.concat([part1,middle_row,part5], axis=0)\n",
    "\n",
    "    return img   \n",
    "\n",
    "def augment_image(img):\n",
    "\n",
    "    img = img / 255.0\n",
    "\n",
    "    img = random_erasing(img, probability=0.5, sl=0.02, sh=0.4, r1=0.3, method='random')\n",
    "\n",
    "    \n",
    "    crop_size = tf.random.uniform(shape=[], minval=420, maxval=480, dtype=tf.int32)\n",
    "    img = tf.image.random_crop(img, size=[crop_size, crop_size, 3])\n",
    "    img = tf.image.resize(img, [480, 480]) \n",
    "    \n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    \n",
    "    img = tf.image.rot90(img, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "    img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "    img = tf.image.random_hue(img, max_delta=0.1)\n",
    "    img = tf.image.random_saturation(img, lower=0.9, upper=1.1)\n",
    "    img = tf.image.random_contrast(img, lower=0.9, upper=1.1)\n",
    "\n",
    "    img = tf.image.random_jpeg_quality(img, min_jpeg_quality=85, max_jpeg_quality=100)\n",
    "\n",
    "    noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01, dtype=tf.float32)\n",
    "    img = tf.add(img, noise)\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "\n",
    "    img = tfa.image.shear_x(img, level=tf.random.uniform([], minval=-0.3, maxval=0.3), replace=0)\n",
    "    img = tfa.image.shear_y(img, level=tf.random.uniform([], minval=-0.3, maxval=0.3), replace=0)\n",
    "\n",
    "\n",
    "    angle = tf.random.uniform([], minval=-np.pi/4, maxval=np.pi/4, dtype=tf.float32)\n",
    "    img = tfa.image.rotate(img, angle)\n",
    "\n",
    "    \n",
    "    \n",
    "    img = tf.image.resize(img, [480, 480]) \n",
    "    img = img * 255.0\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (480, 480))\n",
    "    img = augment_image(img)  \n",
    "    # img = tf.cast(img, tf.uint8)    \n",
    "\n",
    "    # tf.print(\"Final min and max in process_images:\", tf.reduce_min(img), tf.reduce_max(img))\n",
    "    # tf.print(\"Image type: \", img.dtype)\n",
    "\n",
    "    return img\n",
    "\n",
    "def process_image_valid(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (480, 480))\n",
    "    # tf.print(\"Final min and max in process_image_valid:\", tf.reduce_min(img), tf.reduce_max(img))\n",
    "    # img = tf.cast(img, tf.uint8)\n",
    "    return img\n",
    "\n",
    "# Define your dataset processing function\n",
    "def process_path_train(file_path, targets):\n",
    "    img = process_image(file_path)\n",
    "    return img, targets\n",
    "\n",
    "\n",
    "def process_path_valid(file_path, targets):\n",
    "    img = process_image_valid(file_path)\n",
    "    return img, targets\n",
    "\n",
    "def process_path_test(file_path, dummy):\n",
    "    img = process_image_valid(file_path)    \n",
    "    return img, dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[mean_columns]\n",
    "y_valid = valid_df[mean_columns]\n",
    "\n",
    "\n",
    "y_train_transformed = y_train.copy()\n",
    "y_valid_transformed = y_valid.copy()\n",
    "\n",
    "for target, log_base in log_transforms.items():\n",
    "\n",
    "    y_train_transformed[target] = np.log(y_train[target]) / np.log(log_base)\n",
    "    y_valid_transformed[target] = np.log(y_valid[target]) / np.log(log_base)\n",
    "\n",
    "\n",
    "y_train_transformed = scaler_transforms.fit_transform(y_train_transformed)\n",
    "y_valid_transformed = scaler_transforms.transform(y_valid_transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len dataset: 5386\n",
      "Len all train: 43088\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 55000 \n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_images_path = train_df['image_path'].values\n",
    "valid_images_path = valid_df['image_path'].values\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images_path, y_train_transformed))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_images_path, y_valid_transformed))\n",
    "\n",
    "train_dataset = train_dataset.map(process_path_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.map(process_path_valid, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "len_dataset = len(train_dataset) \n",
    "len_all_train = len(train_dataset) * EPOCHS\n",
    "\n",
    "print(f'Len dataset: {len_dataset}')\n",
    "print(f'Len all train: {len_all_train}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCosineDecayWithWarmup(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0, warmup_learning_rate=0.0, warmup_steps=0, name=None):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.alpha = alpha\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"CustomCosineDecayWithWarmup\"):\n",
    "            # Lämpenemisvaihe\n",
    "            learning_rate = tf.cond(\n",
    "                step < self.warmup_steps,\n",
    "                lambda: self.warmup_learning_rate + step / self.warmup_steps * (self.initial_learning_rate - self.warmup_learning_rate),\n",
    "                lambda: self.initial_learning_rate\n",
    "            )\n",
    "            # Kosinilasku lämpenemisen jälkeen\n",
    "            cosine_decay = tf.keras.optimizers.schedules.CosineDecay(\n",
    "                initial_learning_rate=self.initial_learning_rate,\n",
    "                decay_steps=self.decay_steps,\n",
    "                alpha=self.alpha\n",
    "            )\n",
    "            decayed_learning_rate = cosine_decay(step - self.warmup_steps)\n",
    "            \n",
    "            return tf.cond(step < self.warmup_steps, lambda: learning_rate, lambda: decayed_learning_rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_steps\": self.decay_steps,\n",
    "            \"alpha\": self.alpha,\n",
    "            \"warmup_learning_rate\": self.warmup_learning_rate,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"name\": self.name\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "def r2_score_tf(y_true, y_pred):\n",
    "\n",
    "    try: \n",
    "        ss_res = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "        ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true, axis=0)), axis=0)\n",
    "        r2 = 1 - ss_res/(ss_tot + tf.keras.backend.epsilon())\n",
    "        r2 = tf.where(tf.math.is_nan(r2), tf.zeros_like(r2), r2) \n",
    "        return tf.reduce_mean(tf.maximum(r2, 0.0))\n",
    "    except Exception as e:\n",
    "        # print(f'Error in r2_score_tf: {e}')\n",
    "        return float('-inf')\n",
    "\n",
    "\n",
    "\n",
    "image_input = Input(shape=(480, 480, 3), name='image_input')\n",
    "\n",
    "convNeXt_large =  ConvNeXtLarge(weights='imagenet', include_top=False, pooling=None, input_tensor=image_input)\n",
    "\n",
    "convNeXt_large.trainable = True\n",
    "for layer in convNeXt_large.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "avg_pool = GlobalAveragePooling2D()(convNeXt_large.output)\n",
    "max_pool = GlobalMaxPooling2D()(convNeXt_large.output)\n",
    "\n",
    "nas_features_layer = nas_features([avg_pool, max_pool])\n",
    "pass_through_layer = Lambda(lambda x: x, name='nas_features')(nas_features_layer)\n",
    "\n",
    "nas_output = Dense(6, activation='linear', name='final_tune_output')(pass_through_layer)\n",
    "\n",
    "finetune_model = Model(inputs=image_input, outputs=nas_output, name='finetune_model')\n",
    "\n",
    "lr_schedule = CustomCosineDecayWithWarmup(\n",
    "    initial_learning_rate=5e-5,\n",
    "    decay_steps=len_dataset * (EPOCHS - 1),\n",
    "    alpha=0.0,\n",
    "    warmup_learning_rate=1e-6,\n",
    "    warmup_steps=len_dataset ,\n",
    "    name=\"CosineDecayWithWarmup\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Aseta oppimisnopeuden aikataulu\n",
    "finetune_model.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='mae', metrics=['mse', 'mae', 'mape', r2_score_tf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 224,965,867\n",
      "Trainable parameters: 104,633,575\n",
      "Non-trainable parameters: 120,332,292\n",
      "Total parameters from ConvNext: 196,230,336\n",
      "Trainable from ConvNext: 75,904,512\n",
      "Non trainable from ConvNext: 120,325,824\n",
      "Trainable fron NAS: 28,729,063\n",
      "Non trainable from NAS: 6,468\n",
      "Total parameters from NAS: 28,735,531\n"
     ]
    }
   ],
   "source": [
    "trainable_count = sum([tf.size(v).numpy() for v in finetune_model.trainable_weights])\n",
    "non_trainable_count = sum([tf.size(v).numpy() for v in finetune_model.non_trainable_weights])\n",
    "print(f\"Total parameters: {trainable_count + non_trainable_count:,}\")\n",
    "print(f\"Trainable parameters: {trainable_count:,}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
    "\n",
    "print(f'Total parameters from ConvNext: { (trainable_count + non_trainable_count) - (trainable_count_nas + non_trainable_count_nas):,}')\n",
    "print(f'Trainable from ConvNext: {trainable_count - trainable_count_nas:,}')\n",
    "print(f'Non trainable from ConvNext: {non_trainable_count - non_trainable_count_nas:,}')\n",
    "\n",
    "print(f'Trainable fron NAS: {trainable_count_nas:,}')\n",
    "print(f'Non trainable from NAS: {non_trainable_count_nas:,}')\n",
    "print(F'Total parameters from NAS: {trainable_count_nas + non_trainable_count_nas:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "class TrainImageLoggingCallback(Callback):\n",
    "    def __init__(self, log_dir, data):\n",
    "        super(TrainImageLoggingCallback, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.data = data\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Fetch a batch of images\n",
    "        for imgs, tar in self.data.take(1):  # Adjust depending on your dataset structure\n",
    "            \n",
    "            # augmented_images = tf.map_fn(augment_image, imgs)\n",
    "            augmented_images = tf.cast(imgs, tf.uint8)    \n",
    "        \n",
    "            # Prepare the image to write to TensorBoard\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.image(\"Augmented Images\", augmented_images, step=epoch, max_outputs=20)\n",
    "\n",
    "            self.writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging tensorboard to ./logs/lr_test/trial_518_convnextlarge_maxavg_Jkl_kunpaeikamalaolo_2_516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_folder = f\"./logs/lr_test/trial_{study_name}_516\" # MUUTA!\n",
    "\n",
    "print(f'Logging tensorboard to {log_folder}')\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Aseta logitiedostojen hakemisto\n",
    "tensorboard_callback = TensorBoard(log_dir=log_folder, histogram_freq=1, update_freq='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:25:49.829602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [43088,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-05-20 13:25:49.830008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [43088,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:26:04.297274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-05-20 13:26:04.914207: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7db8c5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-20 13:26:04.914251: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-05-20 13:26:06.120902: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-05-20 13:26:06.142558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5386/5386 [==============================] - ETA: 0s - loss: 0.8039 - mse: 1.0880 - mae: 0.8039 - mape: 954.0565 - r2_score_tf: 0.1436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 14:07:47.109436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [10772,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-05-20 14:07:47.109933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [10772,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./NN_search/model_epoch_01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 14:15:32.498824: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2024-05-20 14:15:32.675534: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2024-05-20 14:15:32.857647: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2024-05-20 14:15:32.992025: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2024-05-20 14:15:33.167744: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2024-05-20 14:15:48.432907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [43088,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-05-20 14:15:48.433381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [43088,6]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5386/5386 [==============================] - 2999s 551ms/step - loss: 0.8039 - mse: 1.0880 - mae: 0.8039 - mape: 954.0565 - r2_score_tf: 0.1436 - val_loss: 0.6487 - val_mse: 0.7455 - val_mae: 0.6487 - val_mape: 517.9084 - val_r2_score_tf: 0.2643\n",
      "Epoch 2/8\n",
      "5386/5386 [==============================] - ETA: 0s - loss: 0.6511 - mse: 0.7148 - mae: 0.6511 - mape: 660.3954 - r2_score_tf: 0.2610"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "checkpoint_filepath = './NN_search/model_epoch_{epoch:02d}.h5'\n",
    "\n",
    "model_checkpoint_callback =  tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',  # Tallenna jokaisen eepokin jälkeen\n",
    "    verbose=1,  # Näytä viesti tallennuksesta\n",
    "    save_best_only=False  # Tallenna jokainen eepokki, älä vain parasta\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    model_checkpoint_callback,\n",
    "    tensorboard_callback,\n",
    "    TrainImageLoggingCallback(log_folder, train_dataset)    \n",
    "]\n",
    "\n",
    "history = finetune_model.fit(train_dataset, validation_data=valid_dataset, epochs=EPOCHS, verbose=1, callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "class LayerScale(layers.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "      - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "      init_values (float): Initial value for layer scale. Should be within\n",
    "        [0, 1].\n",
    "      projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "      Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = tf.Variable(\n",
    "            self.init_values * tf.ones((self.projection_dim,))\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "class StochasticDepth(layers.Layer):\n",
    "    \"\"\"Stochastic Depth module.\n",
    "\n",
    "    It performs batch-wise dropping rather than sample-wise. In libraries like\n",
    "    `timm`, it's similar to `DropPath` layers that drops residual paths\n",
    "    sample-wise.\n",
    "\n",
    "    References:\n",
    "      - https://github.com/rwightman/pytorch-image-models\n",
    "\n",
    "    Args:\n",
    "      drop_path_rate (float): Probability of dropping paths. Should be within\n",
    "        [0, 1].\n",
    "\n",
    "    Returns:\n",
    "      Tensor either with the residual path dropped or kept.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_path_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_path_rate\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"drop_path_rate\": self.drop_path_rate})\n",
    "        return config\n",
    "\n",
    "\n",
    "def r2_score_tf(y_true, y_pred):\n",
    "\n",
    "        try: \n",
    "            ss_res = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "            ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true, axis=0)), axis=0)\n",
    "            r2 = 1 - ss_res/(ss_tot + tf.keras.backend.epsilon())\n",
    "            r2 = tf.where(tf.math.is_nan(r2), tf.zeros_like(r2), r2) \n",
    "            return tf.reduce_mean(tf.maximum(r2, 0.0))\n",
    "        except Exception as e:\n",
    "            # print(f'Error in r2_score_tf: {e}')\n",
    "            return float('-inf')\n",
    "\n",
    "\n",
    "    \n",
    "custom_objects = {\"r2_score_tf\": r2_score_tf, \"LayerScale\": LayerScale, \"StochasticDepth\": StochasticDepth, \"CustomCosineDecayWithWarmup\": CustomCosineDecayWithWarmup}\n",
    "\n",
    "for epoch in range(1, EPOCHS+2):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    model = tf.keras.models.load_model(f'./NN_search/model_epoch_{epoch:02d}.h5', custom_objects=custom_objects)\n",
    "    valid_pred = model.predict(valid_dataset, verbose=1)\n",
    "\n",
    "    valid_pred = scaler_transforms.inverse_transform(valid_pred)\n",
    "\n",
    "\n",
    "    for i, target in enumerate(mean_columns):\n",
    "        log_base = log_transforms[target]\n",
    "        valid_pred[:, i] = np.power(log_base, valid_pred[:, i])\n",
    "\n",
    "\n",
    "    R2_valid = r2_score(y_valid, valid_pred)\n",
    "    MSE_valid = mean_squared_error(y_valid, valid_pred)\n",
    "    MAE_valid = mean_absolute_error(y_valid, valid_pred)\n",
    "    MAPE_valid = mean_absolute_percentage_error(y_valid, valid_pred)\n",
    "    print(f'Study name {study_name}')\n",
    "    print(f'Model at epoch {epoch}:\\nR2 : {R2_valid:.5f}, MSE : {MSE_valid:.5f}, MAE : {MAE_valid:.5f}, MAPE : {MAPE_valid:.5f}')\n",
    "\n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model = tf.keras.models.load_model('./NN_search/model_epoch_05.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, log_base in log_transforms.items():\n",
    "   \n",
    "    train_plot[target] = np.log(train_plot[target]) / np.log(log_base)\n",
    "   \n",
    "        \n",
    "train_plot[mean_columns] = scaler_transforms.transform(train_plot[mean_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_transforms)\n",
    "print(scaler_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original[mean_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot[mean_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, columns_names):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "\n",
    "    # Setting up a grid of plots with 2 columns\n",
    "    n_cols = 6\n",
    "    n_rows = len(columns_names) // n_cols + (len(columns_names) % n_cols > 0)\n",
    "\n",
    "    for i, col in enumerate(columns_names):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        sns.kdeplot(df[col], bw_adjust=0.5, fill=False, color='blue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Density')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(train_original, mean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(train_plot, mean_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_training_name = './data/results_finetune_images.pickle'\n",
    "\n",
    "if os.path.exists(results_training_name):\n",
    "    results_training = pd.read_pickle(results_training_name)\n",
    "else:\n",
    "    columns = ['Train R2', 'Train MSE', 'Train MAE', 'Train MAPE', 'Valid R2', 'Valid MSE', 'Valid MAE', 'Valid MAPE', 'Train preds Desc', 'Valid preds Desc', 'Test preds Desc' , 'Original data Desc' 'Kaggle R2', 'Scalers', 'Log/Pot transforms']\n",
    "    results_training = pd.DataFrame(columns = columns)\n",
    "    results_training.index.name = 'Study name'\n",
    "\n",
    "study_name_result = f'{study_name}_finetuned'\n",
    "\n",
    "if study_name_result not in results_training.index:    \n",
    "    results_training.loc[study_name] = [None]*len(results_training.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "submission_df = test_df_copy[['id']].copy()\n",
    "\n",
    "test_images_path = test_df_copy['image_path'].values\n",
    "\n",
    "dummy_y = np.zeros((len(test_df_copy), 6))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images_path, dummy_y))\n",
    "test_dataset = test_dataset.map(process_path_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(16).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "predictions = finetune_model.predict(test_dataset, verbose=1)\n",
    "\n",
    "predictions = scaler_transforms.inverse_transform(predictions)\n",
    "\n",
    "\n",
    "for i, target in enumerate(mean_columns):\n",
    "    print(f'Logpot transforming target: : {target}, log transform : {log_transforms[target]}')\n",
    "    log_base = log_transforms[target] \n",
    "    predictions[:, i] = np.power(log_base, predictions[:, i])\n",
    " \n",
    "\n",
    "# test_preds_desc =  pd.DataFrame(predictions, columns = mean_columns).describe().to_json()\n",
    "# results_training.at[study_name_result, 'Test preds Desc'] = test_preds_desc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[mean_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns = mean_columns)\n",
    "predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_columns = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n",
    "\n",
    "submission_df[target_columns] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_desc = train_original[mean_columns].describe().to_json()\n",
    "results_training.at[study_name_result, 'Original data Desc'] = original_data_desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{str(log_transforms.items())}')\n",
    "print(f'{str(scaler_transforms)}')\n",
    "\n",
    "results_training.at[study_name_result, 'Scalers'] = f'{scaler_transforms}'\n",
    "results_training.at[study_name_result, 'Log/Pot transforms'] = f'{str(log_transforms.items())}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_training.at[study_name_result, 'Kaggle R2'] = None\n",
    "\n",
    "\n",
    "# # results_training.drop('423_std_powerlog_3', inplace=True)\n",
    "# # results_training.head()\n",
    "\n",
    "# for index, row in results_training.iterrows():\n",
    "#     print(f\"Study Name: {index}\")\n",
    "#     print(f'Kaggle R2: {row[\"Kaggle R2\"]}')\n",
    "#     print(f\"Train R2: {row['Train R2']}, Train MSE: {row['Train MSE']}, Train MAE : {row['Train MAE']}, Train MAPE: {row['Train MAPE']}\")\n",
    "#     print(f'Valid R2: {row[\"Valid R2\"]}, Valid MSE: {row[\"Valid MSE\"]}, Valid MAE: {row[\"Valid MAE\"]}, Valid MAPE: {row[\"Valid MAPE\"]}')\n",
    "#     print(\"-\" * 50)\n",
    "#     print(\"Train preds Description:\")\n",
    "#     display(pd.read_json(row['Train preds Desc']))\n",
    "#     print(\"Valid preds Description:\")\n",
    "#     display(pd.read_json(row['Valid preds Desc']))\n",
    "#     print(\"Test preds Description:\")\n",
    "#     display(pd.read_json(row['Test preds Desc']))\n",
    "#     print(\"Original data Description:\")\n",
    "#     display(pd.read_json(row['Original data Desc']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission_df.info())\n",
    "\n",
    "submission_df.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_training_name, 'wb') as f:\n",
    "    results_training.to_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model_output = finetune_model.get_layer('nas_features')\n",
    "feature_model = Model(inputs=finetune_model.input, outputs=feature_model_output.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_paths = train_original['image_path'].values\n",
    "dummy_y = np.zeros((len(train_original), 6))\n",
    "\n",
    "train_all_dataset = tf.data.Dataset.from_tensor_slices((train_all_paths, dummy_y))\n",
    "train_all_dataset = train_all_dataset.map(process_path_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_all_dataset = train_all_dataset.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_features = feature_model.predict(train_all_dataset, verbose=1)\n",
    "\n",
    "train_original[f'model_features_{study_name}'] = train_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = f'./data/train_df.pickle'\n",
    "\n",
    "print(f'Saving train_df to {pickle_file_path}')\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(train_original, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_paths = test_df['image_path'].values\n",
    "dummy_y = np.zeros((len(test_df), 6))\n",
    "\n",
    "test_all_dataset = tf.data.Dataset.from_tensor_slices((test_all_paths, dummy_y))\n",
    "test_all_dataset = test_all_dataset.map(process_path_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_all_dataset = test_all_dataset.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_features = feature_model.predict(test_all_dataset, verbose=1)\n",
    "\n",
    "test_df[f'model_features_{study_name}'] = test_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[f'model_features_{study_name}'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa = test_df[f'model_features_{study_name}'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa = np.array(testa)\n",
    "testa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = f'./data/test_df.pickle'\n",
    "\n",
    "print(f'Saving test_df to {pickle_file_path}')\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(test_df, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
