{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,  RobustScaler\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2M, ConvNeXtBase\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = '426_convnextbase_003_998_1'\n",
    "\n",
    "pickle_file_path = f'./data/test_{study_name}.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "\n",
    "pickle_file_path = f'./data/train_{study_name}.pickle'\n",
    "\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_study_name = '511_convnextbase_avgmax_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', None) \n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ConvNeXtBase(weights='imagenet', include_top=False, pooling=None)\n",
    "base_model.trainable = False\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     print(f'Layer {layer.name}')\n",
    "\n",
    "avg_pool = GlobalAveragePooling2D()(base_model.output)\n",
    "max_pool = GlobalMaxPooling2D()(base_model.output)\n",
    "\n",
    "con = Concatenate()([avg_pool, max_pool])\n",
    "\n",
    "feature_model = Model(inputs = base_model.input, outputs = con)\n",
    "\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (480, 480))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_features_batch(image_paths):\n",
    "    img_batch = np.stack([load_and_preprocess_image(img_path) for img_path in image_paths])\n",
    "    features = feature_model.predict(img_batch, batch_size=batch_size)  \n",
    "    return features\n",
    "\n",
    "image_paths = train_df['image_path'].values\n",
    "\n",
    "features_list = []\n",
    "j = 0\n",
    "for i in range(0, len(image_paths), batch_size):\n",
    "    batch_paths = image_paths[i:i+batch_size]\n",
    "    batch_features = extract_features_batch(batch_paths)\n",
    "    features_list.append(batch_features)\n",
    "    j += 1\n",
    "    if j % 30 == 0:\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        print(f'Clearing session')\n",
    "\n",
    "all_features = np.vstack(features_list)\n",
    "train_df['features_avg'] = list(all_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file path to save the pickle file\n",
    "pickle_file_path = './data/train_convnextbase_df_003_998.pickle'\n",
    "\n",
    "# Save the train_df dataframe as a pickle file\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n",
    "base_model = ConvNeXtBase(weights='imagenet', include_top=False, pooling='avg')\n",
    "base_model.trainable = False\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (480, 480))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_features_batch(image_paths):\n",
    "    img_batch = np.stack([load_and_preprocess_image(img_path) for img_path in image_paths])\n",
    "    features = base_model.predict(img_batch)        \n",
    "    return features\n",
    "\n",
    "image_paths = test_df['image_path'].values\n",
    "\n",
    "features_list = []\n",
    "j = 0\n",
    "for i in range(0, len(image_paths), batch_size):\n",
    "    batch_paths = image_paths[i:i+batch_size]\n",
    "    batch_features = extract_features_batch(batch_paths)\n",
    "    features_list.append(batch_features)\n",
    "    j += 1\n",
    "    if j % 30 == 0:\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        print(f'Clearing session')\n",
    "\n",
    "all_features = np.vstack(features_list)\n",
    "test_df['features_avg'] = list(all_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = './data/test_convnextbase_df_003_998.pickle'\n",
    "\n",
    "# # Save the train_df dataframe as a pickle file\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(test_df, f)\n",
    "\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
